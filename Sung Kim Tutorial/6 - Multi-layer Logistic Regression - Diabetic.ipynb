{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi features linear model\n",
    "X*W = Y matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('./data/diabetes.csv.gz', delimiter=',', dtype=np.float32)\n",
    "x_data = Variable(torch.from_numpy(xy[:, 0:-1]))\n",
    "y_data = Variable(torch.from_numpy(xy[:, [-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([759, 8])\n",
      "torch.Size([759, 1])\n"
     ]
    }
   ],
   "source": [
    "# 8 features = 8 input\n",
    "print(x_data.data.shape)\n",
    "print(y_data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 6)\n",
    "        self.l2 = torch.nn.Linear(6, 4)\n",
    "        self.l3 = torch.nn.Linear(4, 1)\n",
    "\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        # Variables -> l1 -> sigmoid1 -> l2 -> sigmoid2 -> l3 -> sigmoid3 -> pred_y\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred\n",
    "\n",
    "# our model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6934423446655273\n",
      "1 0.6881641745567322\n",
      "2 0.6834784150123596\n",
      "3 0.6793178915977478\n",
      "4 0.6756230592727661\n",
      "5 0.6723389029502869\n",
      "6 0.6694206595420837\n",
      "7 0.6668258309364319\n",
      "8 0.6645169854164124\n",
      "9 0.6624625325202942\n",
      "10 0.6606336832046509\n",
      "11 0.6590055823326111\n",
      "12 0.6575544476509094\n",
      "13 0.6562613844871521\n",
      "14 0.6551085710525513\n",
      "15 0.6540811657905579\n",
      "16 0.6531639099121094\n",
      "17 0.6523458361625671\n",
      "18 0.651614785194397\n",
      "19 0.650962233543396\n",
      "20 0.6503798365592957\n",
      "21 0.6498585343360901\n",
      "22 0.6493924260139465\n",
      "23 0.6489769816398621\n",
      "24 0.6486043334007263\n",
      "25 0.6482718586921692\n",
      "26 0.647973358631134\n",
      "27 0.6477072834968567\n",
      "28 0.6474684476852417\n",
      "29 0.6472549438476562\n",
      "30 0.6470633149147034\n",
      "31 0.6468921303749084\n",
      "32 0.6467378735542297\n",
      "33 0.6466001868247986\n",
      "34 0.6464778780937195\n",
      "35 0.6463664770126343\n",
      "36 0.6462671160697937\n",
      "37 0.6461778879165649\n",
      "38 0.6460989117622375\n",
      "39 0.6460272073745728\n",
      "40 0.6459627151489258\n",
      "41 0.6459051370620728\n",
      "42 0.6458532214164734\n",
      "43 0.6458072066307068\n",
      "44 0.6457645893096924\n",
      "45 0.6457276940345764\n",
      "46 0.6456937789916992\n",
      "47 0.6456636190414429\n",
      "48 0.6456360220909119\n",
      "49 0.6456117630004883\n",
      "50 0.6455895304679871\n",
      "51 0.6455698609352112\n",
      "52 0.6455519795417786\n",
      "53 0.6455356478691101\n",
      "54 0.6455212831497192\n",
      "55 0.645508348941803\n",
      "56 0.6454961895942688\n",
      "57 0.6454857587814331\n",
      "58 0.6454759836196899\n",
      "59 0.6454667448997498\n",
      "60 0.6454597115516663\n",
      "61 0.6454525589942932\n",
      "62 0.6454455852508545\n",
      "63 0.6454400420188904\n",
      "64 0.6454347372055054\n",
      "65 0.645429790019989\n",
      "66 0.6454249024391174\n",
      "67 0.6454216241836548\n",
      "68 0.6454176902770996\n",
      "69 0.6454148292541504\n",
      "70 0.6454114317893982\n",
      "71 0.6454086303710938\n",
      "72 0.645406186580658\n",
      "73 0.6454037427902222\n",
      "74 0.6454019546508789\n",
      "75 0.6453993320465088\n",
      "76 0.6453972458839417\n",
      "77 0.6453956961631775\n",
      "78 0.6453943848609924\n",
      "79 0.645392894744873\n",
      "80 0.6453913450241089\n",
      "81 0.645389974117279\n",
      "82 0.645388662815094\n",
      "83 0.6453874111175537\n",
      "84 0.645386815071106\n",
      "85 0.6453855633735657\n",
      "86 0.6453843712806702\n",
      "87 0.6453835964202881\n",
      "88 0.6453827023506165\n",
      "89 0.6453813910484314\n",
      "90 0.6453803777694702\n",
      "91 0.645379900932312\n",
      "92 0.645379364490509\n",
      "93 0.6453781127929688\n",
      "94 0.6453782916069031\n",
      "95 0.6453770399093628\n",
      "96 0.6453757882118225\n",
      "97 0.6453755497932434\n",
      "98 0.6453746557235718\n",
      "99 0.6453741192817688\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(100):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
